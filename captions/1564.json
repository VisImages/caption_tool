[{"ImageID": 0, "Page": 2, "Type": "Figure", "Imagebbox": [0.5296610169491526, 0.0638953452886537, 0.9173728813559322, 0.29209302325581393], "Caption": "Fig. 2. User interface for the search module of the system. Clockwise from top left: camera view, map, timeline, clip bin.", "DPI": 100, "CaptionBB": [393, 329, 742, 354], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 1, "Page": 2, "Type": "Figure", "Imagebbox": [0.06567796610169492, 0.0638953452886537, 0.4555084745762712, 0.29953488372093023], "Caption": "Fig. 1. Map of one \ufb02oor of the of\ufb01ce space. Shaded areas show public spaces where the sensors are installed. Locations of the six cameras are marked by small triangles.", "DPI": 100, "CaptionBB": [30, 337, 379, 375], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 2, "Page": 2, "Type": "Figure", "Imagebbox": [0.5127118644067796, 0.34325581395348836, 0.9289340101522843, 0.5609302325581396], "Caption": "Fig. 3. Time-lapse capture of the map control while displaying move- ments of several people in the of\ufb01ce space. Location and approximate number of people can be estimated instantaneously for the entire space.", "DPI": 100, "CaptionBB": [393, 615, 742, 653], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 3, "Page": 3, "Type": "Figure", "Imagebbox": [0.14593908629441624, 0.0641860465116279, 0.4048223350253807, 0.16093023255813954], "Caption": "Fig. 4. Determining direction of motion from a sensor map. The sen- sor that is most recently activated is plotted in a bright color, which then slowly fades to black. The direction of the gradient helps to quickly iden- tify the motion at a single frame.", "DPI": 100, "CaptionBB": [42, 187, 391, 239], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 4, "Page": 3, "Type": "Figure", "Imagebbox": [0.5466101694915254, 0.06234495769175448, 0.9300847457627118, 0.22046511627906973], "Caption": "Fig. 5. Timeline control. The top example shows the timeline at its eight- day resolution. A user can zoom in on any portion of the timeline. The example on the bottom shows approximately two-hour range.", "DPI": 100, "CaptionBB": [406, 252, 755, 290], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 5, "Page": 3, "Type": "Figure", "Imagebbox": [0.5444162436548223, 0.2837209302325581, 0.9302030456852792, 0.5069767441860465], "Caption": "Fig. 6. One interactive installation of the system uses a DiamondTouch projection table. Interactions with the table make it useful to have a gesture-based interface that can allow the same manipulations as would normally be performed with a multi-button mouse.", "DPI": 100, "CaptionBB": [406, 559, 755, 611], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 6, "Page": 4, "Type": "Figure", "Imagebbox": [0.5529661016949152, 0.0638953452886537, 0.8919491525423728, 0.2700968956762506], "Caption": "Fig. 8. Top: The timeline in the result display mode. Bottom: Selecting any of the hits causes the clip bin to \ufb01ll up with video clips containing the accompanying video evidence.", "DPI": 100, "CaptionBB": [393, 302, 742, 340], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 7, "Page": 4, "Type": "Figure", "Imagebbox": [0.09110169491525423, 0.06544573288555293, 0.4300847457627119, 0.3395348837209302], "Caption": "Fig. 7. Top: A query is speci\ufb01ed by a gesture traversing a path across 5.1 Gestural query interface the map. The selected sensors are coded in unique colors. Bottom: The query interface in our system is implemented as a front-end to Selected sensors are highlighted with the same color to establish visual an SQL engine that maintains the database of sensor activations. The correspondence. \u201cpath\u201d queries, described above, are formulated by simply drawing", "DPI": 100, "CaptionBB": [30, 371, 743, 429], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 8, "Page": 5, "Type": "Figure", "Imagebbox": [0.5444162436548223, 0.49953488372093025, 0.9302030456852792, 0.6530232558139535], "Caption": "Fig. 13. Tracklet display. In order to achieve the pre-attentive assess- ment of the multitude of tracks and direction of motion we chose an asymmetric swell as a direction cue.", "DPI": 100, "CaptionBB": [406, 716, 755, 754], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 9, "Page": 5, "Type": "Figure", "Imagebbox": [0.6078680203045685, 0.2567441860465116, 0.866751269035533, 0.43627906976744185], "Caption": "Fig. 11. Tracklet graph representation of the track bundle. Each edge, called a Tracklet, represents a contiguous sequence of sensor activa- tions, while nodes represent ambiguities and endpoints.", "DPI": 100, "CaptionBB": [406, 484, 755, 522], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 10, "Page": 5, "Type": "Figure", "Imagebbox": [0.08248730964467005, 0.2567441860465116, 0.4682741116751269, 0.4586046511627907], "Caption": "Fig. 10. Example of crowd movement during a \ufb01re drill.", "DPI": 100, "CaptionBB": [42, 508, 311, 520], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 11, "Page": 5, "Type": "Figure", "Imagebbox": [0.08883248730964467, 0.06325581395348837, 0.9251269035532995, 0.20963177939718083], "Caption": "Fig. 9. Selected frames of the videos from the clip bin. The clips demonstrate automatic handover and tracking mechanisms.", "DPI": 100, "CaptionBB": [42, 238, 650, 250], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 12, "Page": 6, "Type": "Figure", "Imagebbox": [0.08686440677966102, 0.107306198001832, 0.8940677966101694, 0.25395348837209303], "Caption": "Fig. 12. Human-guided track selection process using tracklet tree representation. a) Example of the selection subgraph which includes camera views available for each tracklet, as well as split/join locations where track splicing occurs. Tracklets are shown as edges of the graph passing through the camera views. b) First step of the interactive graph pruning process. One step-lookahead tracklets are presented to the operator. c) Second step of the graph pruning. d) Final track recovered.", "DPI": 100, "CaptionBB": [30, 286, 742, 338], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 13, "Page": 6, "Type": "Figure", "Imagebbox": [0.10913705583756345, 0.413953488372093, 0.8730964467005076, 0.8753488372093023], "Caption": "Fig. 14. User interface of the MERL forensic surveillance system. The interface includes an additional panel that allows for a visual graph traversal and track construction. Parts of the track where the subject is out of the view of the system are highlighted manually for illustration purposes.", "DPI": 100, "CaptionBB": [30, 957, 742, 982], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 14, "Page": 7, "Type": "Figure", "Imagebbox": [0.5444162436548223, 0.0638953452886537, 0.9322033898305084, 0.27813953488372095], "Caption": "Fig. 16. Final assembled track covering a 15-minute period. Locations of the six cameras are marked by small numbered triangles.", "DPI": 100, "CaptionBB": [406, 314, 755, 339], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 15, "Page": 7, "Type": "Figure", "Imagebbox": [0.1016949152542373, 0.06234495769175448, 0.451271186440678, 0.32746123676152195], "Caption": "Fig. 16. Final assembled track covering a 15-minute period. Locations of the six cameras are marked by small numbered triangles.", "DPI": 100, "CaptionBB": [406, 314, 755, 339], "first_confirmed": false, "second_confirmed": false}]