[{"ImageID": 0, "Page": 2, "Type": "Figure", "Imagebbox": [0.496309963099631, 0.4726383245264792, 0.9591836734693877, 0.7020580276303928], "Caption": "Fig. 1. An illustration of the word embedding process: The input of the algorithm is a large corpus of text, which is summarized in a n \u00d7 n matrix M that encodes the relationships between n unique words. Typically M(i, j) records statistical relationships, such as the probability of joint occurrence between wordi and word j . Subsequently, M is factorized and the coordinates in the d n most significant components define the vector representation of words.", "DPI": 100, "CaptionBB": [392, 755, 742, 844], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 1, "Page": 3, "Type": "Table", "Imagebbox": [0.061224489795918366, 0.0784313725490196, 0.9553571428571429, 0.2138188608776844], "Caption": "Table 1. A list of prominent NLP tasks pertinent to word embeddings, gathered from NLP experts. We identify which of these tasks can be performed using existing solutions (adopted in NLP community) and highlight the gaps bridged by the proposed approach .", "DPI": 100, "CaptionBB": [40, 50, 755, 79], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 2, "Page": 3, "Type": "Figure", "Imagebbox": [0.5369897959183674, 0.6405228758169934, 0.9438775510204082, 0.7973856209150327], "Caption": "Fig. 3. An illustration of the intuition behind the projection-finding schemes for an analogy relationship. In a 2D projection, the x-axis captures variation between the two concepts in an analogy relationship. The y-axis captures the variation among pairs.", "DPI": 100, "CaptionBB": [405, 867, 757, 922], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 3, "Page": 3, "Type": "Table", "Imagebbox": [0.05904059040590406, 0.34308366865603385, 0.48523985239852396, 0.47803643518774774], "Caption": "Table 1. A list of prominent NLP tasks pertinent to word embeddings, gathered from NLP experts. We identify which of these tasks can be performed using existing solutions (adopted in NLP community) and highlight the gaps bridged by the proposed approach .", "DPI": 100, "CaptionBB": [40, 50, 755, 79], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 4, "Page": 4, "Type": "Figure", "Imagebbox": [0.03571428571428571, 0.05158569294753184, 0.9502551020408163, 0.2511671335200747], "Caption": "Fig. 4. The domain-specific projection-finding scheme. PCA (a) captures the largest variance in the data, which corresponds to the difference in the meaning of the nouns, whereas the proposed projection schemes (b) (c) capture the singular:plural analogy relationship. In this experiment, the official pretrained Glove vectors are used.", "DPI": 100, "CaptionBB": [28, 281, 742, 323], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 5, "Page": 5, "Type": null, "Imagebbox": [0.06457564575645756, 0.054284748278166116, 0.503690036900369, 0.25671389807573697], "Caption": null, "DPI": null, "CaptionBB": null, "first_confirmed": false, "second_confirmed": false}, {"ImageID": 6, "Page": 5, "Type": null, "Imagebbox": [0.05904059040590406, 0.3862685539461823, 0.48523985239852396, 0.8801956794522552], "Caption": null, "DPI": null, "CaptionBB": null, "first_confirmed": false, "second_confirmed": false}, {"ImageID": 7, "Page": 6, "Type": "Figure", "Imagebbox": [0.03443877551020408, 0.04618758228626328, 0.9502551020408163, 0.2903828197945845], "Caption": "Fig. 7. Word Embedding Visual Explorer. (a) t-SNE embedding panel shows the overall structure of the words of interest. (b) Analogy projection panel enables the exploration among linear projections that highlight an analogy relationship. (c) Pairwise cosine distance histogram panel captures the overall parallelism of the analogy vector orientations. (d) Semantic axis panel shows the words at the extreme ends of an axis that capture a distinct concept.", "DPI": 100, "CaptionBB": [28, 317, 742, 372], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 8, "Page": 7, "Type": "Figure", "Imagebbox": [0.05102040816326531, 0.04078947162499473, 0.9655612244897958, 0.33426704014939307], "Caption": "Fig. 8. Different types of analogies can correspond to very different structures. In (a), (b), (c), the subspace clusters (highlighted by dotted circles) are identified in each of the analogy groups. In (a), closely related analogy pairs are grouped into the same cluster. In (b), currency:country, the two concepts in the analogy are distinct, so the subspace clustering focused on the linear trends within the two groups, instead of among the analogy pairs. In (c), the singular :plural analogy group contains words that have very different concepts (animal, fruit, etc.); therefore, analogy pairs are grouped into clusters not necessarily because they have a similar orientation, but because the larger distances between these different concepts have a stronger influence. The histograms in (d), (e), (f) confirm the observation.", "DPI": 100, "CaptionBB": [40, 362, 755, 443], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 9, "Page": 7, "Type": "Figure", "Imagebbox": [0.05719557195571956, 0.6831646403159529, 0.5, 0.830263155835521], "Caption": "Fig. 8. Different types of analogies can correspond to very different structures. In (a), (b), (c), the subspace clusters (highlighted by dotted circles) are identified in each of the analogy groups. In (a), closely related analogy pairs are grouped into the same cluster. In (b), currency:country, the two concepts in the analogy are distinct, so the subspace clustering focused on the linear trends within the two groups, instead of among the analogy pairs. In (c), the singular :plural analogy group contains words that have very different concepts (animal, fruit, etc.); therefore, analogy pairs are grouped into clusters not necessarily because they have a similar orientation, but because the larger distances between these different concepts have a stronger influence. The histograms in (d), (e), (f) confirm the observation.", "DPI": 100, "CaptionBB": [40, 362, 755, 443], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 10, "Page": 8, "Type": "Figure", "Imagebbox": [0.03443877551020408, 0.044838054620946144, 0.9502551020408163, 0.36507936507936506], "Caption": "Fig. 10. Comparison of Glove and word2Vec word embeddings: (a) Analogy projection (SVM+PCA)-based comparison shows that word2Vec produces a more apparently aligned directions for both syntactic relationships. Here we utilize the hypothesis-testing plot to verify whether the projection captures the truthful structure of the data. As we can see in all four plots, the current error (red triangle) falls outside the possible range of error from random data, which indicates high confidence in the presence of salience structures. (b) The semantic axis plots reveal that the average analogy direction from word2Vec embedding better identifies the true syntactic concept (verb-ing:verb-ed) word2Vec embedding. The mistakes in the case of Glove are marked with red arrows.", "DPI": 100, "CaptionBB": [28, 404, 743, 485], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 11, "Page": 9, "Type": "Figure", "Imagebbox": [0.04974489795918367, 0.31474358768437394, 0.5025510204081632, 0.5042016806722689], "Caption": "Fig. 11. Examining the high distortion regions in the t-SNE.", "DPI": 100, "CaptionBB": [40, 543, 330, 559], "first_confirmed": false, "second_confirmed": false}]