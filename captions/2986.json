[{"ImageID": 0, "Page": 1, "Type": "Figure", "Imagebbox": [0.07838983050847458, 0.1383139499398165, 0.9258474576271186, 0.369321701877801], "Caption": "Fig. 1: Example lineups from our evaluation. Both Fig. 1a and 1b show the same univariate datasets. 19 of these charts are \u201cinnocent\u201d random samples from a Gaussian. One \u201cguilty\u201d chart is mostly random draws, but 20% of samples have an identical value (an extraneous mode). The oversmoothed density plot makes this abnormality difficult to see (participants were only 35% accurate at picking out the correct density plot). Low opacity dot plots, however, make the dark black dot of the mode easier to detect (85% accuracy). See \u00a75.1 for the right answer.", "DPI": 100, "CaptionBB": [61, 406, 712, 478], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 1, "Page": 3, "Type": "Figure", "Imagebbox": [0.048728813559322036, 0.05924418249795603, 0.4766949152542373, 0.22689075630252103], "Caption": "Fig. 2: The commutative diagram in this figure provides a way to evaluate visualizations of population samples. If a change \u03b1 occurs in the population distribution (for instance, the introduction of a flaw such as a region of missing values), we expect to see a proportionally large change in the visualization \u03c9. However, the data to be encoded is often a sample of this unknown distribution: this sampling s can also introduce visual changes in the resulting mapping from data to visualization v.", "DPI": 100, "CaptionBB": [28, 263, 379, 377], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 2, "Page": 3, "Type": "Figure", "Imagebbox": [0.510593220338983, 0.049937965260545905, 0.9502551020408163, 0.23529411764705882], "Caption": "Fig. 3: Different data flaws interact with different visualization map- pings differently based on the setting of design parameters, producing a large number of potential \u03c9s. A visualization and parameter setting that is adept at depicting a certain class of data flaws unambiguously might be a confuser for another type of flaw.", "DPI": 100, "CaptionBB": [393, 263, 745, 335], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 3, "Page": 4, "Type": null, "Imagebbox": [0.07627118644067797, 0.048391469319661456, 0.4639830508474576, 0.5879263530405918], "Caption": null, "DPI": null, "CaptionBB": null, "first_confirmed": false, "second_confirmed": false}, {"ImageID": 4, "Page": 5, "Type": "Figure", "Imagebbox": [0.5127118644067796, 0.049937965260545905, 0.9427966101694916, 0.09955426001733587], "Caption": "Fig. 6: A representation of the \u03b1s that we tested in our study, represent- ing three classes of potential data quality issues. Fig. 5 shows how these flaws might appear across the visualizations we tested in our study.", "DPI": 100, "CaptionBB": [393, 117, 745, 163], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 5, "Page": 5, "Type": "Figure", "Imagebbox": [0.03571428571428571, 0.05117866004962779, 0.47796610169491527, 0.5966386554621849], "Caption": "Fig. 5: Examples of our data flaws we tested, and their visual signatures across dot plots, histograms, and density plots. From left to right are examples of the settings of our design parameters: increasing mark opacity, decreasing the number of bins, and increasing kernel bandwidth, respectively.", "DPI": 100, "CaptionBB": [28, 649, 378, 721], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 6, "Page": 6, "Type": "Figure", "Imagebbox": [0.5338983050847458, 0.048391469319661456, 0.9449152542372882, 0.25583566760037346], "Caption": "Fig. 7: An example lineup. 19 charts are innocent random samples from a Gaussian, one contains a gap where 15 contiguous points have been removed. When there are only a few histogram bins, these bins are unlikely to match exactly with the gap; it can be hard to distinguish true gaps (which will appear as shorter than expected bars) from variation due to sampling error. That is, the coarse binning functions as a confuser from an AVD perspective. Participant accuracy at gap-detection for histograms with 7 bins was 7%, compared to a chance rate of 5%. See \u00a75.3.4 for the correct answer.", "DPI": 100, "CaptionBB": [403, 282, 753, 410], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 7, "Page": 7, "Type": "Figure", "Imagebbox": [0.5318877551020408, 0.2561434073041576, 0.9216101694915254, 0.8338001867413631], "Caption": "Fig. 9: Performance at our flaw detection task across designs and their parameters. Each rightmost column across designs represents a default from Silverman\u2019s Rule, Sturges\u2019 Rule, and 12 VegaLite, respectively.", "DPI": 100, "CaptionBB": [393, 903, 745, 953], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 8, "Page": 7, "Type": "Figure", "Imagebbox": [0.0635593220338983, 0.04621588089330025, 0.4555084745762712, 0.22203488017237463], "Caption": "Fig. 8: Accuracy at identifying which visualization contained a specific 5.3.4 Parameter Settings data flaw, given the size of that flaw in turns of abnormal points (out of 50 total points). Confidence intervals represent 95% bootstrapped C.I.s Density Plot of the trimmed mean. 1.0", "DPI": 100, "CaptionBB": [28, 243, 541, 304], "first_confirmed": false, "second_confirmed": false}]