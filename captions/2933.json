[{"ImageID": 0, "Page": 1, "Type": "Figure", "Imagebbox": [0.08487084870848709, 0.15684885084226868, 0.9077490774907749, 0.4696545284780579], "Caption": "Fig. 1. DeepEyes is a Progressive Visual Analytics system for the analysis of deep neural networks during training. The overview on the training is given by the commonly used loss- and accuracy-curves (a) and the Perplexity Histograms (b) a novel visualization that allows the detection of stable layers. A detailed analysis per layer is performed in three tightly linked visualizations. Degenerated filters are detected in the Activation Heatmap (c), and filter activations are visualized on the Input Map (d). Finally, in the Filter Map (e), relationships among the filters in a layer are visualized.", "DPI": 100, "CaptionBB": [63, 511, 713, 579], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 1, "Page": 2, "Type": "Figure", "Imagebbox": [0.5276752767527675, 0.044838054620946144, 0.9520295202952029, 0.353874883286648], "Caption": "Fig. 2. Overview of a DNN (a). Filter functions are computed by neurons in convolutional layers by applying a kernel or convolution matrix on a subsets of the input (b), called Receptive Field, whose instances are image patches (c). Filter functions are trained to detect different receptive field instances (d) and they are organized in a 3D grid (e) according to the spatial relationships of the receptive fields they compute. 2 D EEP L EARNING P RIMER Deep artificial neural networks are trained on a specific pattern recogni- tion problem, such as image classification. The goal is to predict a class of an unseen sample. A training set consists of a set of high-dimensional inputs x \u2208 Rn together with an associated vector y \u2208 {0, 1}d with \u2211i yi = 1, where d is the total number of labels. The only non-zero component indicates the associated label. The goal of a DNN is to predict the label y\u0303 \u2208 [0, 1]d for an unseen input x\u0303 \u2208 Rn . The prediction is usually in the form of a discrete probability distribution over the possible labels, hence \u2211i y\u0303i = 1.", "DPI": 100, "CaptionBB": [402, 392, 754, 632], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 2, "Page": 3, "Type": "Figure", "Imagebbox": [0.05719557195571956, 0.04753710995158043, 0.9428044280442804, 0.3034547152194211], "Caption": "Fig. 3. In deeper layers, filter functions are trained to detect more complex patterns in larger receptive fields. In convolutional layers a subset of the neurons in the previous layer, the neuronal receptive field, is the input to the filter functions rather than the receptive field instance (a). The same description holds for a fully-connected layer, however, it differs from convolutional layers as the receptive field of a neuron corresponds to the complete input and the neuronal receptive field contains all the neurons in the previous layer (b).", "DPI": 100, "CaptionBB": [30, 333, 744, 388], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 3, "Page": 3, "Type": "Figure", "Imagebbox": [0.5038265306122449, 0.37068160597572364, 0.9528061224489796, 0.5042016806722689], "Caption": "Fig. 4. DeepEyes approach to filter analysis. Instances of receptive fields are sampled and embedded in a 2-dimensional space based on the similarity of the activation in the neuronal receptive-field. Activation of filters is highlighted in the resulting scatterplot and the instances of the receptive fields are visualized in a linked view.", "DPI": 100, "CaptionBB": [395, 552, 745, 620], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 4, "Page": 4, "Type": "Figure", "Imagebbox": [0.5276752767527675, 0.044838054620946144, 0.9630996309963099, 0.3492063492063492], "Caption": "Fig. 5. Overview of the DeepEyes system. The network training overview provided by the loss- and accuracy-curves is integrated with the Perplexity Histograms that allow for the identification of stable layers in the network (blue background). The user focuses on stable layers that are analyzed in detail with three tightly linked visualizations, namely the Activation Heatmap, the Input Map and the Filter Map (red background).", "DPI": 100, "CaptionBB": [402, 386, 752, 467], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 5, "Page": 5, "Type": "Figure", "Imagebbox": [0.03571428571428571, 0.04753710995158043, 0.4870848708487085, 0.27824463118580767], "Caption": "Fig. 6. Perplexity Histograms and their creation. Receptive fields are range [1, |F l |] for every layer l (Figure 6e). Changes in the histograms during training are visualized in a second histogram. Here, green bars", "DPI": 100, "CaptionBB": [30, 297, 745, 324], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 6, "Page": 6, "Type": "Figure", "Imagebbox": [0.047193877551020405, 0.044838054620946144, 0.9655612244897959, 0.19981325863678806], "Caption": "Fig. 7. Detailed analysis performed in DeepEyes. Degenerated filters are detected in the Activation Heatmap (a). The Input Map (b) shows a representation of the input space of a specific layer. By brushing on the Input Map receptive fields are visualized in linked views (insets in (b)). Specific filter activations (c) or the maximum activation of every filter (d) are visualized on the Input Map. The Filter Map (e) allows for the understanding of the relationships between filters that are further investigated in the Input Map. Specific filters are selected by clicking on the activation heatmap or by brushing on the Filter Map.", "DPI": 100, "CaptionBB": [37, 226, 752, 294], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 7, "Page": 7, "Type": "Figure", "Imagebbox": [0.03571428571428571, 0.043488526955629006, 0.9502551020408163, 0.357609710550887], "Caption": "Fig. 8. Analysis of the MNIST network. For each layer the Input- and Filter-Maps are presented alongside their corresponding Activation Heatmaps. We highlight activations for different filters in the different layers. A detailed description of the conclusions, drawn from these visualizations is presented in Section 4.6.", "DPI": 100, "CaptionBB": [30, 395, 747, 437], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 8, "Page": 8, "Type": "Figure", "Imagebbox": [0.507380073800738, 0.04618758228626328, 0.9501845018450185, 0.34173669467787116], "Caption": "Fig. 9. Fine tuning of a pretrained neural network. Deep eyes allows for the identification of layers that do not need retraining, e.g. Conv1. Unrecognized input data are highlighted in the Perplexity Histograms and in the Maximum Activation visualization of the Input Map, here highlighting data that is labeled as Geometric Compositions which are not recognized by the original network. Furthermore, a filter trained to detect faces is not discriminative given the Romantic and Vintage labels.", "DPI": 100, "CaptionBB": [402, 371, 754, 466], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 9, "Page": 9, "Type": "Figure", "Imagebbox": [0.03571428571428571, 0.4834345458490163, 0.48154981549815495, 0.8860877684407096], "Caption": "Fig. 10. Mitotic Figures detection. A DNN is trained to detect mitotic sorFlow [1] or Theano [42], and to the analysis of different and more figures in histological images (a). Filters in the first convolutional layer exotic network architectures, such as Recurrent Neural Networks [30] Conv1 are highly associated with mitotic figures (b). Labeled data are and Deep Residual Networks [14]. Finally, we want to apply DeepEyes separated in the Input Map of the first fully-connected layer FC1 (c). After for the analysis of DNNs in several application contexts, giving insights removing FC1 the prediction layer (d) still shows very strong separation, on their design.", "DPI": 100, "CaptionBB": [30, 948, 745, 1020], "first_confirmed": false, "second_confirmed": false}]