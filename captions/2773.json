[{"ImageID": 0, "Page": 1, "Type": "Figure", "Imagebbox": [0.1483050847457627, 0.16001937629640564, 0.8728813559322033, 0.426704014939309], "Caption": "Fig. 1. Some application scenarios for Gaussian Cubes. Top left: screenshot of an interactive session of visual analysis of the Bureau of Transportation Statistic (BTS) on-time performance data, including 160 million flights over a 25-year time span. Gaussian Cubes enable visualizations that show the slope of the model that describes how flights get later as the day progresses, and these models can be computed over arbitrary subsets of the data at interactive rates. This makes it easy to spot Southwest Airlines\u2019s alleged practice of indefinitely grounding (but not canceling) delayed flights in early 2014. Subsequently, the Department of Transportation levied on Southwest Airlines the largest fine ever received by an airline [27]. Right: visualization of a model heatmap of a color-color diagram of a large astronomical catalog (the Sloan Digital Sky Survey Data Release 7 [1]), which includes 51 million stars after data cleaning. Bottom left: Gaussian Cubes used as the backing store for a large number of earthquake simulations, enabling fast computation of Principal Component Analysis over arbitrary data subsets. See Section 6 for more details.", "DPI": 100, "CaptionBB": [74, 475, 725, 596], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 1, "Page": 2, "Type": "Figure", "Imagebbox": [0.04449152542372881, 0.051492244513459906, 0.4745762711864407, 0.21195144724556492], "Caption": "Fig. 2. A summary of our proposed workflow for visual exploratory mod- eling. In current practice, the building of models to explain or explore a dataset typically happens through repeated scans of the dataset. As datasets grow larger, the latency of even a single scan becomes pro- hibitive. In this paper, we introduce Gaussian Cubes, which extends data cubes in order to support low-latency exploratory modeling. Gaus- sian Cubes enables the computation of model parameters in real-time; with it, we can build interactive visualizations that compare, for example, thousands of principal component analyses over tens of millions of data points on the order of a second (see Section 6.2).", "DPI": 100, "CaptionBB": [28, 239, 380, 373], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 2, "Page": 2, "Type": "Figure", "Imagebbox": [0.5423728813559322, 0.060794570094855255, 0.9110169491525424, 0.3081232492997199], "Caption": "Fig. 3. On the left, an example of a data cube as it is typically created. From the relation on the top left, the analyst picks a set of column to \u201ccube\u201d. The traditional data cube table (bottom left) collects all possible aggregations \u2014commonly known as \u201cgroup by\u201ds\u2014 along the selected columns. On the right, we show the added columns of a data cube model for Gaussian Cubes, which makes a distinction between \u201cindexing vari- ables\u201d and \u201cmodeling variables\u201d (top right). Gaussian Cubes create data cubes with added columns (bottom right) containing sums of polynomial expansions of the modeling variables (by default, up to degree 2). As we explain in Section 3.2, these sums suffice to find best-fitting linear models in any of the modeling variables. It also enables other modeling techniques, as we discuss further in Section 4.", "DPI": 100, "CaptionBB": [392, 353, 745, 513], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 3, "Page": 3, "Type": "Figure", "Imagebbox": [0.0847457627118644, 0.05614340730415758, 0.4639830508474576, 0.19234360410831003], "Caption": "Fig. 4. The implementation of Gaussian Cubes are based on Nanocubes [32], which are an implementation of spatiotemporal cubes. Such cubes generate intermediate aggregates that correspond to filtering operations that naturally appear in spatial and temporal queries, such as queries over time intervals and contiguous geographic regions.", "DPI": 100, "CaptionBB": [41, 219, 393, 287], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 4, "Page": 3, "Type": "Figure", "Imagebbox": [0.5572033898305084, 0.05304263211035913, 0.923728813559322, 0.217383717381677], "Caption": "Fig. 5. In addition to sample counts partitioned over the indexing vari- ables (the same kind of aggregation scheme used in other visualization- specific data cubes), Gaussian Cubes store the sums of the modeling variables, and the sums of their pairwise products. Gaussian Cubes require no changes in the way previous systems lay out their indexing structures, and so the expressivity of the \u201cslicing and dicing\u201d capabilities is unchanged. In exchange for the additional memory usage, we get the ability to fit a number of models over large datasets, at interactive rates.", "DPI": 100, "CaptionBB": [405, 246, 757, 354], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 5, "Page": 4, "Type": "Figure", "Imagebbox": [0.5, 0.04994185691656068, 0.951530612244898, 0.44529069412586303], "Caption": "Fig. 6. Algorithm for progressive refinement of a projected Gaussian Cube.", "DPI": 100, "CaptionBB": [393, 490, 743, 519], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 6, "Page": 5, "Type": "Table", "Imagebbox": [0.06887755102040816, 0.20634920634920634, 0.9489795918367347, 0.3622782446311858], "Caption": "Table 2. An illustration of a synthetic dataset design to assess the querying performance of Gaussian Cubes. We note that the query time is essentially proportional to the size of the output image; the query time per cell is essentially constant (the apparent decrease is likely due to a constant overhead from network latency). In addition, the overall time is dominated by the calculation of the Principal Components Analysis. This computation is currently done on the client side in Javascript; there are clear opportunities for parallelization.", "DPI": 100, "CaptionBB": [40, 397, 755, 452], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 7, "Page": 5, "Type": "Table", "Imagebbox": [0.07627118644067797, 0.054593019707258356, 0.9385593220338984, 0.1465919701213819], "Caption": "Table 1. Summary of the datasets and respective Gaussian Cubes used in our experiments. We note that both the overall memory usage and build times are comparable to that of Nanocubes [32]. (In column Indexing Schema, the numbers in the parentheses indicate how many bits are used to store that dimension. Column |dim| means the total number of dimensions stored in each Gaussian Cube.)", "DPI": 100, "CaptionBB": [40, 165, 755, 214], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 8, "Page": 6, "Type": "Figure", "Imagebbox": [0.03571428571428571, 0.05304263211035913, 0.4745762711864407, 0.24374030652896378], "Caption": "Fig. 7. Approximate scatterplots along non-indexing dimensions. The multivariate normals stored at every level of the data structures of Gaus- partition schema doesn\u2019t directly offer a spatial subdivision scheme for sian Cubes in yet another way to produce approximate scatterplots. the axes being presented, but the traversal algorithm can adaptively Recall that normal distributions have a remarkable property: when subdivide nodes to maximally increase the resolved details of the plot. transformed by affine transformations (a linear transformation followed Here, we show a set of 300 projected Gaussians along different axes by a translation), normal distributions remain normal. If values X are of the SDSS dataset. Even though this is a tiny fraction of the available drawn from a multivariate normal N(\u00b5, \u03a3), the distribution of the X nodes in the graph, they are sufficient to highlight a well-known feature values transformed by a matrix M is given by N(M\u00b5, M\u03a3M T ). As a", "DPI": 100, "CaptionBB": [28, 271, 745, 372], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 9, "Page": 7, "Type": "Figure", "Imagebbox": [0.2076271186440678, 0.051492244513459906, 0.7966101694915254, 0.30158730158730157], "Caption": "Fig. 8. Showcasing interactive exploration workflows enabled by Gaussian Cubes. The figure on the left shows a visualization of 51 million stars aggregated spatially in what astronomers call a color diagram: it shows that most of the visible stars follow a specific one-dimensional curve, the stellar locus. In this visualization, the hue corresponds to the average brightness of the stars in each bin. Users can select different principal subspaces (middle figure) by clicking on different parts of the image. The principal subspaces can be used to generate approximate PCA plots (see Section 5) and compute a colormap based on distances between the subspaces of each region of the plot, and get a visual clustering of places along the diagram where the internal variation of the set of stars is comparable.", "DPI": 100, "CaptionBB": [41, 335, 756, 416], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 10, "Page": 8, "Type": "Figure", "Imagebbox": [0.15889830508474576, 0.05614340730415758, 0.8326271186440678, 0.4211017740429505], "Caption": "Fig. 9. By colormapping the rate at which flights become late during the day, we typically see snowballing effects specific to pairs of airlines and locations (such as ExpressJet\u2019s case). In Southwest\u2019s case, however, the effects are spread throughout the country. We have found evidence in the press that Southwest Airlines plans flight schedules differently from other companies, and that this difference may account for the effect [21]. cell will be light blue. We define the distances between the cells to The schema for the Gaussian Cube we use in this section uses three be the distances between the principal subspaces of the samples. In indexing variables: a 25-bit spatial dimension encoding the latitude our experiment, we choose the first three principal components of each and longitude of the flight arrival, a categorical variable encoding cell. This choice was mostly arbitrary; different choices will produce 31 different airlines, and a time variable binned at 1 day resolution different clusterings, but the general workflow is the same. Let P0 be indicating the date of arrival of the flight. The modeling variable schema the principal subspace of the user clicked cell C0 , and let Pk be the contains two variables: delay at arrival and flight arrival time. For principal subspace of one of the other cells Ck . The matrices P are computational convenience, we encode both of the modeling variables defined by computing the eigendecomposition U\u03a3U T for each cell, and in fractions of a day.", "DPI": 100, "CaptionBB": [28, 468, 743, 629], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 11, "Page": 9, "Type": null, "Imagebbox": [0.06779661016949153, 0.05304263211035913, 0.4936440677966102, 0.14141472513361494], "Caption": null, "DPI": null, "CaptionBB": null, "first_confirmed": false, "second_confirmed": false}]