[{"ImageID": 0, "Page": 1, "Type": "Figure", "Imagebbox": [0.19083969465648856, 0.16049041297935104, 0.8358778625954199, 0.31636363636363635], "Caption": "Fig. 1: Knowledge generation model for visual analytics: The model consists of computer and human parts. The left hand side illustrates a visual analytics system, whereas the right hand side illustrates the knowledge generation process of the human. The latter is a reasoning process composed of exploration, veri\ufb01cation, and knowledge generation loops. Visual analytics pursues a tight integration of human and machine by enabling the user to interact with the system. These interactions are illustrated in Figure 2.", "DPI": 100, "CaptionBB": [106, 370, 755, 425], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 1, "Page": 3, "Type": "Figure", "Imagebbox": [0.1851145038167939, 0.08084439528023599, 0.8454198473282442, 0.31545454545454543], "Caption": "Fig. 2: Detailed part of the process model including action and cognition paths. Actions can either lead directly to visual analytic components (blue arrows) or to their mappings (blue, dashed arrows). Humans can observe reactions of the system (red arrows) in order to generate \ufb01ndings.", "DPI": 100, "CaptionBB": [73, 377, 788, 405], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 2, "Page": 4, "Type": "Figure", "Imagebbox": [0.16221374045801526, 0.07346976401179942, 0.8377862595419847, 0.32727272727272727], "Caption": "Fig. 3: Relating the process model for knowledge generation in visual analytics to other models and theories. Similarity is illustrated by color and position. A detailed illustration of interactions between the human and computer is shown in Figure 2.", "DPI": 100, "CaptionBB": [61, 387, 776, 415], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 3, "Page": 5, "Type": "Figure", "Imagebbox": [0.1183206106870229, 0.061670353982300884, 0.4694656488549619, 0.19441371681415928], "Caption": "Fig. 4: Van Wijks model including Green et al.\u2019s changes [13, 14] and they can be distinguished when considering the associated loops. High labels. level actions are inspired by the veri\ufb01cation loop and are based on", "DPI": 100, "CaptionBB": [73, 224, 787, 252], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 4, "Page": 6, "Type": "Figure", "Imagebbox": [0.1049618320610687, 0.061670353982300884, 0.45038167938931295, 0.21727272727272728], "Caption": "Fig. 5: Human Cognition Model by Green et al. [13, 14].", "DPI": 100, "CaptionBB": [93, 250, 379, 264], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 5, "Page": 7, "Type": "Figure", "Imagebbox": [0.5258823529411765, 0.24818181818181817, 0.9258474576271186, 0.4445454545454545], "Caption": "Fig. 7: Comparative model application to different kinds of systems. Jigsaw represents visual analytics, Knime data mining, Tableau infor- mation visualization, and H ARVEST applications from the provenance domain. Strength of support for functionalities/components of our model is indicated by the weight of the lines.", "DPI": 100, "CaptionBB": [438, 494, 790, 563], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 6, "Page": 7, "Type": "Figure", "Imagebbox": [0.1016949152542373, 0.06019542772861357, 0.875, 0.1872727272727273], "Caption": "Fig. 6: Illustration of validation steps using Jigsaw. In 6a left, the person Daniel Keim (left list) is connected to the concept of text, displayed on the right. To \ufb01nd evidence for this fact, the Document Cluster View of the publications is opened (6b). After inspection of the cluster labels, a document from the visualizing,interaction,text cluster is examined in detail. This document is evidence that the fact presented in the list view in 6a is true. An example for the Tablet View can be seen in 6c.", "DPI": 100, "CaptionBB": [73, 205, 788, 260], "first_confirmed": false, "second_confirmed": false}]