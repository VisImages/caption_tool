[{"ImageID": 0, "Page": 2, "Type": "Figure", "Imagebbox": [0.03571428571428571, 0.054207402234636874, 0.9502551020408163, 0.25957049486461253], "Caption": "Fig. 1: A parallel coordinate plot used to aid model-developers in constructing a decision tree for classifying facial expressions. On the left, a model-developer can select facial features and time series attributes to investigate. On the main panel, each polyline represents a video and its attribute values are shown on the axes. The first axis indicates the classification labels. Scatterplots show the distributions of values and labels. Brushing is used to create and highlight decisions. The above example shows the three decisions used to obtain the smile classification.", "DPI": 100, "CaptionBB": [28, 285, 743, 344], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 1, "Page": 3, "Type": "Figure", "Imagebbox": [0.04974489795918367, 0.04443086592178771, 0.9655612244897959, 0.1111111111111111], "Caption": "Fig. 2: Example visualization images in the training dataset. Four classes: bubble charts, treemaps, parallel coordinates, and bar graphs.", "DPI": 100, "CaptionBB": [57, 130, 738, 147], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 2, "Page": 3, "Type": "Figure", "Imagebbox": [0.5510204081632653, 0.1531279178338002, 0.9311224489795918, 0.37441643323996265], "Caption": "Fig. 3: The two pipelines, representing the machine- and human- centric approaches respectively, for constructing decision trees that can detect the visual representation featured in a visualization images.", "DPI": 100, "CaptionBB": [405, 411, 755, 456], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 3, "Page": 5, "Type": "Figure", "Imagebbox": [0.04974489795918367, 0.054207402234636874, 0.9655612244897959, 0.22315592903828202], "Caption": "Fig. 4: A parallel coordinates plot used in the human-centric approach for image classification. Axes are ordered by GainRatio() in Eq. (2). Comparing the \u201cbest\u201d ranked axis (GS107Mi1) and the second \u201cbest\u201d (GS305Mi1), a human developer would consider that the second \u201cbest\u201d has a few advantages (e.g., separability between green and blue lines).", "DPI": 100, "CaptionBB": [41, 246, 756, 291], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 4, "Page": 6, "Type": "Table", "Imagebbox": [0.05343511450381679, 0.24929971988795518, 0.46564885496183206, 0.3070006983240223], "Caption": "Table 3: Performance of the classifiers with a skewed dataset", "DPI": 100, "CaptionBB": [49, 245, 357, 262], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 5, "Page": 6, "Type": "Table", "Imagebbox": [0.06377551020408163, 0.0718954248366013, 0.45663265306122447, 0.12978524743230627], "Caption": "Table 2: Performance of the classifiers with a small dataset", "DPI": 100, "CaptionBB": [54, 150, 353, 167], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 6, "Page": 6, "Type": "Table", "Imagebbox": [0.06377551020408163, 0.16059757236227826, 0.45663265306122447, 0.2184873949579832], "Caption": "Table 2: Performance of the classifiers with a small dataset", "DPI": 100, "CaptionBB": [54, 150, 353, 167], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 7, "Page": 7, "Type": "Figure", "Imagebbox": [0.04974489795918367, 0.05560405027932961, 0.9655612244897959, 0.28291316526610644], "Caption": "Fig. 5: (a) A decision tree constructed using the human-centric approach. Considers the top path (smile classification, see also Fig. 1), the model developer picked M6 (mouth width), M8 (lip curvature), and M2 (inner brow movement) (O6). (b) At the decision-tree root, for the same M6 measurement, M6:ar1 was found not useful, and M6:peak (see Fig. 6b) less useful because of the large overlapping pattern (O1, O2, O6). (c) Eventually M6:fft1 was selected. (d) At the leaf node (smile), M4:Std (brow horizontal movement) was not used because of an outlier (O4).", "DPI": 100, "CaptionBB": [40, 305, 755, 364], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 8, "Page": 7, "Type": "Figure", "Imagebbox": [0.04580152671755725, 0.3530900837988827, 0.5019083969465649, 0.5514141061452514], "Caption": "Fig. 5: (a) A decision tree constructed using the human-centric approach. Considers the top path (smile classification, see also Fig. 1), the model developer picked M6 (mouth width), M8 (lip curvature), and M2 (inner brow movement) (O6). (b) At the decision-tree root, for the same M6 measurement, M6:ar1 was found not useful, and M6:peak (see Fig. 6b) less useful because of the large overlapping pattern (O1, O2, O6). (c) Eventually M6:fft1 was selected. (d) At the leaf node (smile), M4:Std (brow horizontal movement) was not used because of an outlier (O4).", "DPI": 100, "CaptionBB": [40, 305, 755, 364], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 9, "Page": 8, "Type": "Figure", "Imagebbox": [0.03571428571428571, 0.05001745810055866, 0.9502551020408163, 0.4453781512605043], "Caption": "Fig. 7: Two flowcharts showing information flows with the two approaches constructing a decision tree in Case Study A (Section 4).", "DPI": 100, "CaptionBB": [53, 485, 717, 502], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 10, "Page": 9, "Type": null, "Imagebbox": [0.04770992366412214, 0.05001745810055866, 0.49809160305343514, 0.3433135474860336], "Caption": null, "DPI": null, "CaptionBB": null, "first_confirmed": false, "second_confirmed": false}]