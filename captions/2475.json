[{"ImageID": 0, "Page": 1, "Type": "Figure", "Imagebbox": [0.11176470588235295, 0.16237724666314507, 0.8776470588235294, 0.4209090909090909], "Caption": "Figure 1. MovExp is a versatile visualization tool which supports the HCI experts in evaluating user interfaces by means of data coming from motion capture and biomechanical simulation. In this example, HCI experts were interested in \ufb01nding a input region on a vertical public display, where movements are accurate, fast and least fatiguing. The screenshot on the right shows the analysis in our tool MovExp. The circular directions visualization was used to brush horizontal movements, and movements with high throughput and low muscle activation were selected on a scatter plot. These two selections were combined using an and operator. Note how data is visualized on top of a photo of the public display, showing its spatial setup. We call this a case-speci\ufb01c visualization. The Ergonomics aspect of the data is visualized using a muscle view. The optimal region was identi\ufb01ed to be in the middle of the display.", "DPI": 100, "CaptionBB": [95, 476, 744, 569], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 1, "Page": 4, "Type": "Table", "Imagebbox": [0.5233050847457628, 0.06090425157312871, 0.9194915254237288, 0.2963636363636364], "Caption": "Table 2. Translation from general visualization tasks (Section 3.1) to spe- ci\ufb01c requirements for the visualization tool (Section 3.3). The technical implementation of these requirements in described in Section 4; speci\ufb01c subsections are given in the right column.", "DPI": 100, "CaptionBB": [436, 336, 788, 389], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 2, "Page": 4, "Type": "Table", "Imagebbox": [0.0826271186440678, 0.06090425157312871, 0.5, 0.39805646106576376], "Caption": "Table 2. Translation from general visualization tasks (Section 3.1) to spe- ci\ufb01c requirements for the visualization tool (Section 3.3). The technical implementation of these requirements in described in Section 4; speci\ufb01c subsections are given in the right column.", "DPI": 100, "CaptionBB": [436, 336, 788, 389], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 3, "Page": 5, "Type": "Figure", "Imagebbox": [0.5047058823529412, 0.06272727272727273, 0.9094117647058824, 0.30818181818181817], "Caption": "Figure 2. Muscle views (top row) show the activation patterns of muscles. This supports the analysis of the Ergonomics aspect of the data. This visual encoding is clearly more intuitive than the corresponding bar plot shown at the bottom.", "DPI": 100, "CaptionBB": [427, 355, 779, 408], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 4, "Page": 6, "Type": "Figure", "Imagebbox": [0.5127118644067796, 0.06090425157312871, 0.9294117647058824, 0.44363636363636366], "Caption": "Figure 3. Example of de\ufb01nition of a case-speci\ufb01c visualization. Starting from a photo of the physical setup used in the HCI case study, the domain expert draws a corresponding 2D sketch. The polygons are annotated to relate them to variables in the data set. The resulting visualization shows the average accuracy for movements starting from the respective targets \u2013 fully integrated into the Linking & Brushing environment.", "DPI": 100, "CaptionBB": [435, 505, 786, 585], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 5, "Page": 7, "Type": "Figure", "Imagebbox": [0.07203389830508475, 0.06908755762877519, 0.489406779661017, 0.23766366237509268], "Caption": "Figure 4. Top-down (blue) pointing movements are slower than bottom- up (red) movements. This was a surprising outcome of our analysis regarding basic human factors. Compare with Figure 5.", "DPI": 100, "CaptionBB": [62, 278, 414, 318], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 6, "Page": 7, "Type": "Figure", "Imagebbox": [0.15411764705882353, 0.3109090909090909, 0.40588235294117647, 0.5081818181818182], "Caption": "Figure 4. Top-down (blue) pointing movements are slower than bottom- up (red) movements. This was a surprising outcome of our analysis regarding basic human factors. Compare with Figure 5.", "DPI": 100, "CaptionBB": [62, 278, 414, 318], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 7, "Page": 7, "Type": "Figure", "Imagebbox": [0.5011764705882353, 0.06636363636363636, 0.9194915254237288, 0.3118181818181818], "Caption": "Figure 6. The user clicks directly on a muscle in the muscle view, which creates a smooth selection corresponding to its activation. The 3D trajectory visualization reveals the spatial pattern for which this muscle is recruited the most.", "DPI": 100, "CaptionBB": [427, 360, 777, 413], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 8, "Page": 8, "Type": "Figure", "Imagebbox": [0.510593220338983, 0.06745089641764589, 0.9294117647058824, 0.2972727272727273], "Caption": "Figure 8. MovExp was used to compare three interaction paradigms for plane control: Steering wheel, bird and arm \ufb02exor. The muscle views show clearly the different amount of activation involved by the three paradigms. The Steering Wheel was selected as the best choice for plane control.", "DPI": 100, "CaptionBB": [436, 344, 786, 411], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 9, "Page": 8, "Type": "Figure", "Imagebbox": [0.08352941176470588, 0.05926759036199941, 0.5023529411764706, 0.2381818181818182], "Caption": "Figure 7. Design of a \ufb01tness game focused on training the back muscles. First, the muscles on the back are selected, which shall be trained by playing the game. The involved directions and areas can be seen in the aspect- and case-speci\ufb01c visualizations in (b) and (c). Selecting the most dominant directions and areas reveals two distinguished performance areas in 3D space, shown in (d).", "DPI": 100, "CaptionBB": [71, 276, 423, 356], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 10, "Page": 9, "Type": "Figure", "Imagebbox": [0.07627118644067797, 0.06908755762877519, 0.4851694915254237, 0.22293371147492905], "Caption": "Figure 9. HCI experts clustered their data set according to muscular for the aspect-speci\ufb01c views (e.g., muscle view) will be to express coactivation patterns in 3D pointing movements. Their interest was to variability among users instead of point averages.", "DPI": 100, "CaptionBB": [62, 265, 777, 295], "first_confirmed": false, "second_confirmed": false}]