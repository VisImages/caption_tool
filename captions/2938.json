[{"ImageID": 0, "Page": 1, "Type": "Figure", "Imagebbox": [0.11016949152542373, 0.17087208947470023, 0.9107142857142857, 0.4631185807656396], "Caption": "Fig. 1. ConceptVector supports interactive construction of lexicon-based concepts. Here the user creates a new unipolar concept (1) by adding initial keywords related to \u2018tidal flooding\u2019 (2). The system recommends related words along with their semantic groupings (3), also shown in a scatterplot (4), revealing word- and cluster-level relationships. Irrelevant words can be specified to improve recommendation quality (5). Concepts (9) can then be used to rank document corpora (10). Document scores can be visualized in a scatterplot based on concepts such as \u2018tidal flooding\u2019 and \u2018money\u2019 (7). Users can further refine concepts based on results (8).", "DPI": 100, "CaptionBB": [73, 510, 723, 578], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 1, "Page": 2, "Type": "Figure", "Imagebbox": [0.038135593220338986, 0.051492244513459906, 0.4872881355932203, 0.19327731092436978], "Caption": "Fig. 2. Workflow of ConceptVector, involving human- and machine-side tasks in a collaborative manner. See Section 5 for details.", "DPI": 100, "CaptionBB": [28, 219, 378, 248], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 2, "Page": 4, "Type": "Figure", "Imagebbox": [0.13983050847457626, 0.051492244513459906, 0.826271186440678, 0.3099906629318394], "Caption": "Fig. 3. Comparison of tweet messages from Hillary Clinton and from Donald Trump during the U.S. 2016 presidential election. The odd ratios of the top 10 categories show differences between the two candidates in (a). The analysis on actual keywords contributing to their corresponding category scores reveals limitations of using the prebuilt lexicon in (b). Red dotted categories do not make sense, because an irrelevant top word is counted dominantly. For example, keywords such as \u2018bush\u2019 in the \u2018plant\u2019 category and \u2018looking\u2019 in the \u2018hipster\u2019 category are not relevant to their categories.", "DPI": 100, "CaptionBB": [28, 351, 743, 406], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 3, "Page": 5, "Type": "Figure", "Imagebbox": [0.14795918367346939, 0.05228758169934641, 0.8698979591836735, 0.2698412698412698], "Caption": "Fig. 4. PCA 2D projection of NASDAQ 100 companies with their k-means clustering labels color-coded, where the feature vector of each company is computed from its tweets\u2019 word count in each of 194 concepts. The clustering using the prebuilt lexica shows some outliers (a), where further investigation of contributing words shows that the company name itself acts trivially as strong signals, such as \u2018dish\u2019 in Dish Network Corporation. Another cluster is shown to be formed because of the common word \u2018technology\u2019 in their names. After excluding them in the initial lexicon, more meaningful clusters are revealed. For example, Marriott and TripAdvisor form a cluster because of words in \u2018tourism,\u2019 \u2018vacation,\u2019 and \u2018sleep\u2019 concepts (olive green with a black border). Companies with negative sentiments such as \u2018ridicules,\u2019 \u2018neglect,\u2019 \u2018kill,\u2019 and \u2018hate\u2019 were also clustered together (bright red dots with red border).", "DPI": 100, "CaptionBB": [40, 305, 757, 400], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 4, "Page": 5, "Type": "Figure", "Imagebbox": [0.05102040816326531, 0.39589169000933705, 0.5025510204081632, 0.5676937441643324], "Caption": "Fig. 5. Distribution of comments across the \u2018tidal flooding\u2019 (X-axis) and the \u2018economy\u2019 (Y-axis) concepts. A comment that has scored relatively high on both concepts is selected (orange box). The content of the corresponding comment within this dataset is shown.", "DPI": 100, "CaptionBB": [40, 620, 390, 675], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 5, "Page": 7, "Type": "Figure", "Imagebbox": [0.5444915254237288, 0.541414725133615, 0.940677966101695, 0.7264239028944911], "Caption": "Fig. 6. Boxplots comparing the three methods in terms of precision, recall, and the size of resulting lexicon. ConceptVector shows the best result.", "DPI": 100, "CaptionBB": [405, 796, 756, 838], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 6, "Page": 8, "Type": "Figure", "Imagebbox": [0.5169491525423728, 0.1817248026529948, 0.902542372881356, 0.3755232522653979], "Caption": "Fig. 7. Spearman\u2019s rank correlation coefficient results with respect to the number of keywords used for training. KDE stands for kernel density estimation, LogiReg for logistic regression, W2V for word2vec [31], LSI for latent semantic indexing, and GloVe for GloVe [38].", "DPI": 100, "CaptionBB": [392, 417, 742, 472], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 7, "Page": 8, "Type": "Table", "Imagebbox": [0.08290816326530612, 0.0784313725490196, 0.9017857142857143, 0.1400560224089636], "Caption": "Table 1. Precision, recall, and average number of keywords per concept for three methods constructing user-defined concepts. The values in parentheses indicate the standard deviation. See Section 6.1.2 for details.", "DPI": 100, "CaptionBB": [27, 50, 742, 79], "first_confirmed": false, "second_confirmed": false}]