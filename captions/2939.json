[{"ImageID": 0, "Page": 1, "Type": "Figure", "Imagebbox": [0.09110169491525423, 0.12746123676152193, 0.8940677966101694, 0.45098039215686275], "Caption": "Fig. 1. The user interface of our system, showing classification results of the ImageNet ILSVRC dataset [56] using GoogLeNet [64]. (a) The class hierarchy with all classes under bird group selected. (b) The confusion matrix showing misclassified samples only. The bands indicate the selected classes in both dimensions. (c) The sample viewer shows selected samples grouped by actual class.", "DPI": 100, "CaptionBB": [63, 495, 711, 537], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 1, "Page": 4, "Type": "Figure", "Imagebbox": [0.5127118644067796, 0.051492244513459906, 0.961864406779661, 0.18207282913165268], "Caption": "Fig. 2. Filtering out diagonal cells and cells whose values are < 10 to retain repetitive confusions. Near-diagonal cells correspond to highly similar classes while off-diagonal cells often indicate data quality issues.", "DPI": 100, "CaptionBB": [402, 209, 752, 251], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 2, "Page": 5, "Type": "Figure", "Imagebbox": [0.038135593220338986, 0.04994185691656068, 0.9502551020408163, 0.36134453781512604], "Caption": "Fig. 3. The Response Map: (a) Illustrating how the row that corresponds to class trollybus is computed. Each column represents the average responses of a neuron in the selected layer. (b, c) The response maps of layers inception-1 and inception-6 in GoogLeNet [64]. The rows represent the classes and are ordered by the class hierarchy depicted to the left of each map. The wheeled vehicle group is selected, and the neurons are sorted by their relevance to it (Eq. 2). The most relevant neurons in layer inception-6 can separate the classes in this group from other classes, while inception-1 can only separate higher-level groups. (d) Pose-based detectors of vehicles have high responses among mammals as well.", "DPI": 100, "CaptionBB": [30, 400, 745, 468], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 3, "Page": 6, "Type": "Figure", "Imagebbox": [0.04974489795918367, 0.04994185691656068, 0.9661016949152542, 0.21381886087768442], "Caption": "Fig. 4. Feature detectors at layer inception-6 in GoogLeNet that show high response to samples of class strawberry. We depict the top-9 images in ILSVRC validation set that activate each detector most, along with the corresponding saliency maps (computed using FeatureVis [24]).", "DPI": 100, "CaptionBB": [37, 242, 751, 271], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 4, "Page": 6, "Type": "Figure", "Imagebbox": [0.5127551020408163, 0.7042054228080336, 0.9597457627118644, 0.8982259570494865], "Caption": "Fig. 5. The correlation matrix between the samples of class mushroom, along with a sample-level response map. Each block in the matrix cor- responds to a sub-class of similar samples (e.g. red mushrooms).", "DPI": 100, "CaptionBB": [402, 975, 752, 1017], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 5, "Page": 7, "Type": "Table", "Imagebbox": [0.5360169491525424, 0.8282364305599715, 0.9216101694915254, 0.8748832866479925], "Caption": "Table 1. Performance of baseline vs. improved architectures.", "DPI": 100, "CaptionBB": [420, 945, 719, 961], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 6, "Page": 7, "Type": "Figure", "Imagebbox": [0.5084745762711864, 0.5739728646684986, 0.9540816326530612, 0.6928104575163399], "Caption": "Fig. 7. The adapted AlexNet architecture. The added branches are marked with a dotted box. These branches impose the class hierarchy during the training phase and are eliminated after training completion.", "DPI": 100, "CaptionBB": [395, 755, 745, 797], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 7, "Page": 7, "Type": "Figure", "Imagebbox": [0.04449152542372881, 0.048391469319661456, 0.9385593220338984, 0.24556489262371617], "Caption": "Fig. 6. The confusion matrix after the first epoch (a), the second epoch (b), and the final epoch (c) during the training of AlexNet [34]. The network starts to distinguish high-level groups already after the first epoch. The hierarchy viewers show the corresponding group-level accuracies.", "DPI": 100, "CaptionBB": [30, 275, 745, 304], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 8, "Page": 8, "Type": "Figure", "Imagebbox": [0.5190677966101694, 0.048391469319661456, 0.9533898305084746, 0.3249299719887955], "Caption": "Fig. 9. Rotation-invariant (left) vs. rotation-sensitive classes (right).", "DPI": 100, "CaptionBB": [402, 362, 733, 378], "first_confirmed": false, "second_confirmed": false}, {"ImageID": 9, "Page": 8, "Type": "Figure", "Imagebbox": [0.0548469387755102, 0.646125116713352, 0.4872448979591837, 0.9215686274509803], "Caption": "Fig. 8. Color-invariant (left) vs. color-sensitive classes (right).", "DPI": 100, "CaptionBB": [37, 1002, 341, 1018], "first_confirmed": false, "second_confirmed": false}]